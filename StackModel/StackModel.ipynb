{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw8f6jliKGpb",
        "outputId": "4935cb47-1025-459f-f76e-9dcb48d686ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "✅ Best Threshold: 0.43\n",
            "Accuracy: 0.6626126126126126\n",
            "F1 Score: 0.6924024640657084\n",
            "AUC: 0.7287275932678292\n",
            "Mean Evaluation Metric (Accuracy + F1 + AUC) / 3: 0.69458088998205\n"
          ]
        }
      ],
      "source": [
        "# 1. 라이브러리 임포트\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier\n",
        "from google.colab import drive\n",
        "\n",
        "# 2. 구글 드라이브 마운트 및 데이터 로드\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "train_df = pd.read_csv('/content/gdrive/MyDrive/2025-1 Pattern recognition/train_processed.csv', engine='python')\n",
        "test_df = pd.read_csv('/content/gdrive/MyDrive/2025-1 Pattern recognition/test_processed.csv', engine='python')\n",
        "\n",
        "# 3. Feature Engineering 함수 정의\n",
        "def add_features(X):\n",
        "    X = X.copy()\n",
        "    # 기존\n",
        "    for col in ['n_tokens_content', 'num_hrefs', 'num_self_hrefs']:\n",
        "        if col in X.columns:\n",
        "            X[f'log_{col}'] = np.log1p(X[col].clip(lower=0))\n",
        "\n",
        "    if 'n_tokens_content' in X.columns and 'num_hrefs' in X.columns:\n",
        "        X['tokens_x_hrefs'] = X['n_tokens_content'] * X['num_hrefs']\n",
        "        X['links_per_token'] = X['num_hrefs'] / (X['n_tokens_content'] + 1)\n",
        "\n",
        "    # 추가 상호작용 항\n",
        "    if 'global_subjectivity' in X.columns and 'global_sentiment_polarity' in X.columns:\n",
        "        X['subj_x_polarity'] = X['global_subjectivity'] * X['global_sentiment_polarity']\n",
        "\n",
        "    if 'average_token_length' in X.columns and 'n_tokens_content' in X.columns:\n",
        "        X['avglen_x_tokens'] = X['average_token_length'] * X['n_tokens_content']\n",
        "\n",
        "    return X\n",
        "\n",
        "# 4. 데이터 분리 및 가공\n",
        "X = train_df.drop(columns=['id', 'y', 'shares'])\n",
        "y = train_df['y']\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "X_train_fe = add_features(X_train)\n",
        "X_valid_fe = add_features(X_valid)\n",
        "\n",
        "# 5. 개별 모델 정의 (튜닝 반영)\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=1000,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.01,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.8,\n",
        "    gamma=0.1,\n",
        "    min_child_weight=2,\n",
        "    eval_metric='auc',\n",
        "    tree_method='hist',\n",
        "    device='cuda',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "lgb_model = LGBMClassifier(\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.01,\n",
        "    max_depth=3,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.8,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=0.1,\n",
        "    device='CPU',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "cat_model = CatBoostClassifier(\n",
        "    iterations=1000,\n",
        "    depth=6,\n",
        "    learning_rate=0.01,\n",
        "    l2_leaf_reg=4,\n",
        "    eval_metric='AUC',\n",
        "    random_seed=42,\n",
        "    verbose=0,\n",
        "    task_type='CPU'\n",
        ")\n",
        "\n",
        "# 6. 스태킹 모델 정의\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_model),\n",
        "        ('lgb', lgb_model),\n",
        "        ('cat', cat_model)\n",
        "    ],\n",
        "    final_estimator=LogisticRegression(max_iter=300),\n",
        "    cv=15,\n",
        "    n_jobs=-1,\n",
        "    passthrough=False\n",
        ")\n",
        "\n",
        "# 7. 학습\n",
        "stack_model.fit(X_train_fe, y_train)\n",
        "\n",
        "# 8. 예측 확률\n",
        "y_prob_valid = stack_model.predict_proba(X_valid_fe)[:, 1]\n",
        "\n",
        "# 9. Threshold 튜닝 (성능 균형 기준)\n",
        "best_score = 0\n",
        "best_thresh = 0.5\n",
        "\n",
        "for thresh in np.arange(0.42, 0.48, 0.0005):\n",
        "    preds = (y_prob_valid > thresh).astype(int)\n",
        "    acc = accuracy_score(y_valid, preds)\n",
        "    f1 = f1_score(y_valid, preds)\n",
        "    auc = roc_auc_score(y_valid, y_prob_valid)\n",
        "    mean_metric = (acc + f1 + auc) / 3\n",
        "    if mean_metric > best_score:\n",
        "        best_score = mean_metric\n",
        "        best_thresh = thresh\n",
        "        best_acc, best_f1, best_auc = acc, f1, auc\n",
        "\n",
        "# 10. 출력\n",
        "print(f\"✅ Best Threshold: {best_thresh:.2f}\")\n",
        "print(\"Accuracy:\", best_acc)\n",
        "print(\"F1 Score:\", best_f1)\n",
        "print(\"AUC:\", best_auc)\n",
        "print(\"Mean Evaluation Metric (Accuracy + F1 + AUC) / 3:\", best_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "2JbOJdHlKJAa",
        "outputId": "b2db56b5-afb0-496c-a342-1a506f4b9435"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      id  y_predict    y_prob\n",
            "0   4979          0  0.234247\n",
            "1  15552          0  0.407629\n",
            "2  29370          1  0.613724\n",
            "3  37272          0  0.241613\n",
            "4   6836          1  0.483548\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_d1d31eb4-b7ff-4216-a4b1-4aa0d31fa913\", \"prediction.csv\", 6166423)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 11. 학습 때 쓰인 컬럼 저장\n",
        "feature_cols = X_train_fe.columns.tolist()\n",
        "\n",
        "# 12. 테스트 데이터 전처리\n",
        "X_test_raw  = test_df.drop(columns=['id'], errors='ignore')   # id 제외\n",
        "X_test_fe   = add_features(X_test_raw)                        # 동일 FE 적용\n",
        "\n",
        "# 모델에 넣을 전용 DataFrame만 따로 만듬.\n",
        "X_test_model = X_test_fe[feature_cols].reindex(columns=feature_cols, fill_value=0)\n",
        "\n",
        "# 13. 예측\n",
        "y_prob_test = stack_model.predict_proba(X_test_model)[:, 1]\n",
        "y_pred_test = (y_prob_test > best_thresh).astype(int)\n",
        "\n",
        "# 14. test_df 원본은 그대로 두고 예측 컬럼만 추가\n",
        "test_df['y_predict'] = y_pred_test\n",
        "test_df['y_prob']    = y_prob_test\n",
        "\n",
        "# 15. 저장 및 다운로드\n",
        "output_path = '/content/prediction.csv'\n",
        "test_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(test_df[['id', 'y_predict', 'y_prob']].head())\n",
        "from google.colab import files\n",
        "files.download(output_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Accuracy: 0.6626126126126126\n",
        "F1 Score: 0.6924024640657084\n",
        "AUC: 0.7287275932678292\n",
        "Mean Evaluation Metric (Accuracy + F1 + AUC) / 3: 0.69458088998205"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. 라이브러리 임포트\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier\n",
        "from google.colab import drive\n",
        "\n",
        "# 2. 구글 드라이브 마운트 및 데이터 로드\n",
        "train_df = pd.read_csv('train_processed.csv', engine='python')\n",
        "test_df = pd.read_csv('test_processed.csv', engine='python')\n",
        "\n",
        "# 3. Feature Engineering 함수 정의\n",
        "def add_features(X):\n",
        "    X = X.copy()\n",
        "    # 기존\n",
        "    for col in ['n_tokens_content', 'num_hrefs', 'num_self_hrefs']:\n",
        "        if col in X.columns:\n",
        "            X[f'log_{col}'] = np.log1p(X[col].clip(lower=0))\n",
        "\n",
        "    if 'n_tokens_content' in X.columns and 'num_hrefs' in X.columns:\n",
        "        X['tokens_x_hrefs'] = X['n_tokens_content'] * X['num_hrefs']\n",
        "        X['links_per_token'] = X['num_hrefs'] / (X['n_tokens_content'] + 1)\n",
        "\n",
        "    # 추가 상호작용 항\n",
        "    if 'global_subjectivity' in X.columns and 'global_sentiment_polarity' in X.columns:\n",
        "        X['subj_x_polarity'] = X['global_subjectivity'] * X['global_sentiment_polarity']\n",
        "\n",
        "    if 'average_token_length' in X.columns and 'n_tokens_content' in X.columns:\n",
        "        X['avglen_x_tokens'] = X['average_token_length'] * X['n_tokens_content']\n",
        "\n",
        "    return X\n",
        "\n",
        "# 4. 데이터 분리 및 가공\n",
        "X = train_df.drop(columns=['id', 'y', 'shares'])\n",
        "y = train_df['y']\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "X_train_fe = add_features(X_train)\n",
        "X_valid_fe = add_features(X_valid)\n",
        "\n",
        "# 5. 개별 모델 정의 (튜닝 반영)\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=487,\n",
        "    max_depth=3,\n",
        "    learning_rate= 0.022783546678795837,\n",
        "    subsample= 0.9865934283784953,\n",
        "    colsample_bytree= 0.6270846419992482,\n",
        "    gamma= 0.8172927176529761,\n",
        "    min_child_weight=2,\n",
        "    eval_metric='auc',\n",
        "    tree_method='hist',\n",
        "    device='cuda',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "lgb_model = LGBMClassifier(\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.01,\n",
        "    max_depth=6,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.8,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=0.1,\n",
        "    device='CPU',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "cat_model = CatBoostClassifier(\n",
        "    iterations=2487,\n",
        "    depth=10,\n",
        "    learning_rate=0.0029934141977455034,\n",
        "    l2_leaf_reg=3.513721573697142,\n",
        "    eval_metric='AUC',\n",
        "    random_seed=42,\n",
        "    verbose=0,\n",
        "    task_type='CPU'\n",
        ")\n",
        "\n",
        "\n",
        "# 6. 스태킹 모델 정의\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_model),\n",
        "        ('lgb', lgb_model),\n",
        "        ('cat', cat_model)\n",
        "    ],\n",
        "    final_estimator=LogisticRegression(max_iter=300),\n",
        "    cv=15,\n",
        "    n_jobs=-1,\n",
        "    passthrough=False\n",
        ")\n",
        "\n",
        "# 7. 학습\n",
        "stack_model.fit(X_train_fe, y_train)\n",
        "\n",
        "# 8. 예측 확률\n",
        "y_prob_valid = stack_model.predict_proba(X_valid_fe)[:, 1]\n",
        "\n",
        "# 9. Threshold 튜닝 (성능 균형 기준)\n",
        "best_score = 0\n",
        "best_thresh = 0.5\n",
        "\n",
        "for thresh in np.arange(0.42, 0.48, 0.0005):\n",
        "    preds = (y_prob_valid > thresh).astype(int)\n",
        "    acc = accuracy_score(y_valid, preds)\n",
        "    f1 = f1_score(y_valid, preds)\n",
        "    auc = roc_auc_score(y_valid, y_prob_valid)\n",
        "    mean_metric = (acc + f1 + auc) / 3\n",
        "    if mean_metric > best_score:\n",
        "        best_score = mean_metric\n",
        "        best_thresh = thresh\n",
        "        best_acc, best_f1, best_auc = acc, f1, auc\n",
        "\n",
        "# 10. 출력\n",
        "print(f\"✅ Best Threshold: {best_thresh:.2f}\")\n",
        "print(\"Accuracy:\", best_acc)\n",
        "print(\"F1 Score:\", best_f1)\n",
        "print(\"AUC:\", best_auc)\n",
        "print(\"Mean Evaluation Metric (Accuracy + F1 + AUC) / 3:\", best_score)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
