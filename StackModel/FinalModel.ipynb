{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZJslG7Q4m9x",
        "outputId": "66e50af4-2450-49fd-c374-42346dbec837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "✅ Best Threshold: 0.42\n",
            "Accuracy: 0.6596846846846847\n",
            "F1 Score: 0.693446946642321\n",
            "AUC: 0.7316701430325531\n",
            "Mean Evaluation Metric (Accuracy + F1 + AUC) / 3: 0.6949339247865196\n"
          ]
        }
      ],
      "source": [
        "# 1. Library import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier\n",
        "from google.colab import drive\n",
        "\n",
        "# 2. Drive mount & load the data\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "train_df = pd.read_csv('/content/gdrive/MyDrive/2025-1 Pattern recognition/train_processed.csv', engine='python')\n",
        "test_df = pd.read_csv('/content/gdrive/MyDrive/2025-1 Pattern recognition/test_processed.csv', engine='python')\n",
        "\n",
        "# 3. Feature Engineering function 정의\n",
        "def add_features(X):\n",
        "    X = X.copy()\n",
        "    # 기존\n",
        "    for col in ['n_tokens_content', 'num_hrefs', 'num_self_hrefs']:\n",
        "        if col in X.columns:\n",
        "            X[f'log_{col}'] = np.log1p(X[col].clip(lower=0))    # log transformation\n",
        "\n",
        "    if 'n_tokens_content' in X.columns and 'num_hrefs' in X.columns:\n",
        "        X['tokens_x_hrefs'] = X['n_tokens_content'] * X['num_hrefs']\n",
        "        X['links_per_token'] = X['num_hrefs'] / (X['n_tokens_content'] + 1)\n",
        "\n",
        "    # 추가 상호작용 항\n",
        "    if 'global_subjectivity' in X.columns and 'global_sentiment_polarity' in X.columns:\n",
        "        X['subj_x_polarity'] = X['global_subjectivity'] * X['global_sentiment_polarity']\n",
        "\n",
        "    if 'average_token_length' in X.columns and 'n_tokens_content' in X.columns:\n",
        "        X['avglen_x_tokens'] = X['average_token_length'] * X['n_tokens_content']\n",
        "\n",
        "    return X\n",
        "\n",
        "# 4. Columns drop & data split\n",
        "X = train_df.drop(columns=['id', 'y', 'shares'])\n",
        "y = train_df['y']\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "X_train_fe = add_features(X_train)\n",
        "X_valid_fe = add_features(X_valid)\n",
        "\n",
        "# 5. 개별 모델 정의 (튜닝 반영)\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=487,\n",
        "    max_depth=3,\n",
        "    learning_rate= 0.022783546678795837,\n",
        "    subsample= 0.9865934283784953,\n",
        "    colsample_bytree= 0.6270846419992482,\n",
        "    gamma= 0.8172927176529761,\n",
        "    min_child_weight=2,\n",
        "    eval_metric='auc',\n",
        "    tree_method='hist',\n",
        "    device='cuda',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "lgb_model = LGBMClassifier(\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.01,\n",
        "    max_depth=6,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.8,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=0.1,\n",
        "    gpu_use_dp=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "cat_model = CatBoostClassifier(\n",
        "    iterations=2487,\n",
        "    depth=10,\n",
        "    learning_rate=0.0029934141977455034,\n",
        "    l2_leaf_reg=3.513721573697142,\n",
        "    eval_metric='AUC',\n",
        "    random_seed=42,\n",
        "    verbose=0,\n",
        "    task_type='CPU',\n",
        "    od_type='Iter',             # Early-Stopping 기준\n",
        "    od_wait=80                  # 80회\n",
        "\n",
        ")\n",
        "\n",
        "# ── 클래스 불균형 가중치 세팅 ──────────\n",
        "pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
        "\n",
        "xgb_model.set_params(scale_pos_weight=pos_weight)      # XGBoost\n",
        "lgb_model.set_params(is_unbalance=True)                # LightGBM\n",
        "cat_model.set_params(class_weights=[1.0, pos_weight])  # CatBoost\n",
        "# ───────────────────────────────────────────────\n",
        "\n",
        "\n",
        "# 6. Stacking model\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_model),\n",
        "        ('lgb', lgb_model),\n",
        "        ('cat', cat_model)\n",
        "    ],\n",
        "    final_estimator=LogisticRegression(max_iter=300),\n",
        "    cv=15,\n",
        "    n_jobs=-1,\n",
        "    passthrough=False\n",
        ")\n",
        "\n",
        "# 7. Train\n",
        "stack_model.fit(X_train_fe, y_train)\n",
        "\n",
        "# 8. Prediction\n",
        "y_prob_valid = stack_model.predict_proba(X_valid_fe)[:, 1]\n",
        "\n",
        "# 9. Threshold Tuning (성능 균형 기준)\n",
        "best_score = 0\n",
        "best_thresh = 0.5\n",
        "\n",
        "for thresh in np.arange(0.42, 0.48, 0.0005):\n",
        "    preds = (y_prob_valid > thresh).astype(int)\n",
        "    acc = accuracy_score(y_valid, preds)\n",
        "    f1 = f1_score(y_valid, preds)\n",
        "    auc = roc_auc_score(y_valid, y_prob_valid)\n",
        "    mean_metric = (acc + f1 + auc) / 3\n",
        "    if mean_metric > best_score:\n",
        "        best_score = mean_metric\n",
        "        best_thresh = thresh\n",
        "        best_acc, best_f1, best_auc = acc, f1, auc\n",
        "\n",
        "# 10. Print Result\n",
        "print(f\"✅ Best Threshold: {best_thresh:.2f}\")\n",
        "print(\"Accuracy:\", best_acc)\n",
        "print(\"F1 Score:\", best_f1)\n",
        "print(\"AUC:\", best_auc)\n",
        "print(\"Mean Evaluation Metric (Accuracy + F1 + AUC) / 3:\", best_score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 때 쓰인 컬럼 저장\n",
        "feature_cols = X_train_fe.columns.tolist()\n",
        "\n",
        "# 테스트 데이터 전처리\n",
        "X_test_raw  = test_df.drop(columns=['id'], errors='ignore')   # id 제외\n",
        "X_test_fe   = add_features(X_test_raw)                        # 동일 FE 적용\n",
        "\n",
        "# 모델에 넣을 전용 DataFrame만 따로 만듬.\n",
        "X_test_model = X_test_fe[feature_cols].reindex(columns=feature_cols, fill_value=0)\n",
        "\n",
        "# 예측\n",
        "y_prob_test = stack_model.predict_proba(X_test_model)[:, 1]\n",
        "y_pred_test = (y_prob_test > best_thresh).astype(int)\n",
        "\n",
        "# test_df 원본은 그대로 두고 예측 컬럼만 추가\n",
        "test_df['y_predict'] = y_pred_test\n",
        "test_df['y_prob']    = y_prob_test\n",
        "\n",
        "# 저장 및 다운로드\n",
        "output_path = '/content/prediction.csv'\n",
        "test_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(test_df[['id', 'y_predict', 'y_prob']].head())\n",
        "from google.colab import files\n",
        "files.download(output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "x_ahNG4odigs",
        "outputId": "f486df5d-0511-4cf4-c5a4-af90d2132efd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id  y_predict    y_prob\n",
            "0   4979          0  0.261903\n",
            "1  15552          0  0.404382\n",
            "2  29370          1  0.644493\n",
            "3  37272          0  0.268367\n",
            "4   6836          1  0.514373\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_54f9992d-5f1b-4bac-96be-c6232507c60c\", \"prediction.csv\", 6166487)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}